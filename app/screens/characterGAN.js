import React, { useState, useEffect } from 'react';
import { SafeAreaView, View, StyleSheet, Text, Dimensions, Button, Image } from 'react-native';
import { useRouter } from "expo-router";
import { CustomBtn,StepIndicator } from '../../src/components'
import * as tf from '@tensorflow/tfjs';
import * as tfReactNative from '@tensorflow/tfjs-react-native';
import * as ImagePicker from 'expo-image-picker';
import { fetch } from '@tensorflow/tfjs-react-native';
import { images } from '../../constants';
import * as FileSystem from 'expo-file-system';
import { receiveImages, uploadImageToServer } from '../../backend/getGif';
import { Asset } from 'expo-asset';

const { width, height } = Dimensions.get('window'); // Get the screen dimensions

const characterGAN = () => {
  const router = useRouter();
  const [imag, setImages] = useState([]);
  const [imageUri, setImageUri] = useState(null);
  const [prediction, setPrediction] = useState(null);
  const [characterImage, setCharacterImage] = useState(null);
  const [photoUri, setPhotoUri] = useState(null); //handleNextPressì—ì„œ ì‚¬ìš©í•˜ê¸°ìœ„í•´
  const stepLabels = ['Step 1', 'Step 2', 'Step 3', 'Step 4'];

  useEffect(() => {
    const unsubscribe = receiveImages(setImages); // ì´ë¯¸ì§€ ìˆ˜ì‹  ê¸°ëŠ¥ì„ getGifì—ì„œ ê°€ì ¸ì˜´.
    return () => unsubscribe();
  }, []);

  // ê°¤ëŸ¬ë¦¬ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ëŠ” í•¨ìˆ˜
  const selectImage = async () => {
    let result = await ImagePicker.launchImageLibraryAsync({
      mediaTypes: ImagePicker.MediaTypeOptions.Images,
      allowsEditing: true,
      aspect: [4, 3],
      quality: 1,
    });
    if (!result.canceled) {
      setImageUri(result.assets[0].uri);
    }
  };

  // ì¹´ë©”ë¼ë¡œ ì‚¬ì§„ì„ ì°ëŠ” í•¨ìˆ˜
  const takePicture = async () => {
    let result = await ImagePicker.launchCameraAsync({
      mediaTypes: ImagePicker.MediaTypeOptions.Images,
      allowsEditing: true,
      aspect: [4, 3],
      quality: 1,
    });

    if (!result.canceled) {
      setImageUri(result.assets[0].uri);
    }
  };

  const classifyImage = async () => {
    if (!imageUri) return;
    try {
      const fileInfo = await FileSystem.getInfoAsync(imageUri);
      const imageData = await FileSystem.readAsStringAsync(fileInfo.uri, { encoding: FileSystem.EncodingType.Base64 });
      const imageBuffer = tf.util.encodeString(imageData, 'base64').buffer;
      const imageTensor = tfReactNative.decodeJpeg(new Uint8Array(imageBuffer));

      // ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ë¦¬ì‚¬ì´ì¦ˆ ë° ì •ê·œí™”)
      const resizedImage = tf.image.resizeBilinear(imageTensor, [224, 224]); // ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë§ì¶¤
      const normalizedImage = resizedImage.div(255.0); // ì •ê·œí™”
      const batchedImage = normalizedImage.expandDims(0); // ë°°ì¹˜ ì°¨ì› ì¶”ê°€

      console.log('Loading model...');
      const model = await tf.loadLayersModel('https://teachablemachine.withgoogle.com/models/WTW8Mtqh_/model.json');
      console.log('Model loaded successfully');

      console.log('Making predictions...');
      const predictions = await model.predict(batchedImage);
      console.log('Predictions made successfully');

      const maxIndex = predictions.as1D().argMax().dataSync()[0];
      const labels = ["long_woman", "short_woman", "long_man", "short_man"];
      setPrediction(labels[maxIndex]);

      // ì˜ˆì¸¡ëœ ê²°ê³¼ì— ë”°ë¼ ìºë¦­í„° ì´ë¯¸ì§€ ì„¤ì •
      const characterImages = {
        long_woman: images.long_woman,
        short_woman: images.short_woman,
        long_man: images.long_man,
        short_man: images.short_man
      };
      setCharacterImage(characterImages[labels[maxIndex]]);

      console.log('Prediction:', images[labels[maxIndex]]);

      const predictedImage = characterImages[labels[maxIndex]];
      const uri = await loadImageUri(predictedImage); //ìºë¦­í„° ì´ë¯¸ì§€ì˜ uri
      setPhotoUri(uri); // ìƒíƒœ ë³€ìˆ˜ë¡œ ì„¤ì •

    } catch (error) {
      console.error("Error classifying image: ", error);
      alert("ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.");
    }
  };

  useEffect(() => {
    (async () => {
      await tf.ready(); // TensorFlow.jsê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤.
    })();
  }, []);

  // ìºë¦­í„° ì´ë¯¸ì§€ì˜ urië¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
  const loadImageUri = async (imagePath) => {
    const asset = Asset.fromModule(imagePath);
    await asset.downloadAsync();
    return asset.localUri;
  };

  const handleNextPress = async () => {
    // ë¨¼ì € ë‹¤ìŒ í™”ë©´ìœ¼ë¡œ ì´ë™
    router.push('tabs/mainScreen');

    try {
      console.log(photoUri);
      uploadImageToServer(photoUri) // ìºë¦­í„° ì´ë¯¸ì§€ë¥¼ ì„œë²„ë¡œë³´ë‚´ëŠ” í•¨ìˆ˜
        .then(() => {
          console.log('ì—…ë¡œë“œ ì„±ê³µ');
          // ì—…ë¡œë“œ ì„±ê³µ ì²˜ë¦¬
        })
        .catch((error) => {
          console.error('ì´ë¯¸ì§€ ì—…ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ:', error);
          // ì—…ë¡œë“œ ì‹¤íŒ¨ ì²˜ë¦¬
        })
        .finally(() => {
          setUploading(false); // ì—…ë¡œë“œ ì¢…ë£Œ
        });
    } catch (error) {
      console.error('ì´ë¯¸ì§€ ë¡œë”© ì¤‘ ì—ëŸ¬ ë°œìƒ:', error);
      setUploading(false); // ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì—…ë¡œë“œ ìƒíƒœë¥¼ ì¢…ë£Œë¡œ ë³€ê²½
    }
  };


  return (
    <SafeAreaView style={styles.safeContainer}>
      <StepIndicator
        steps={stepLabels}
        currentStep={3}
      />
      <View style={styles.container}>
        <Text style={styles.title}>ë‚˜ë§Œì˜ ìºë¦­í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”ğŸƒğŸ»</Text>
        <View style={styles.buttonContainer}>
          <Button title="ê°¤ëŸ¬ë¦¬ì—ì„œ ì„ íƒ" onPress={selectImage} />
          <Button title="ì‚¬ì§„ ì°ê¸°" onPress={takePicture} />
        </View>
        {characterImage && (
          <View>
            <Image source={characterImage} style={styles.image} />
            <Button title="ë‹¤ì‹œ ì„ íƒ" onPress={() => setImageUri(null)} />
          </View>
        )}
        {!characterImage && imageUri && (
          <View>
            <Image source={{ uri: imageUri }} style={styles.image} />
            <Button title="ì´ë¯¸ì§€ ë¶„ë¥˜" onPress={classifyImage} />
          </View>
        )}
        {prediction && <Text style={styles.prediction}>{`Prediction: ${prediction}`}</Text>}
        <CustomBtn
          buttonStyle={styles.Btn}
          title="ë‹¤ìŒ"
          onPress={handleNextPress}
        />
      </View>
    </SafeAreaView>
  );
};

const styles = StyleSheet.create({
  safeContainer: {
    flex: 1,
    backgroundColor: '#ffffff',
  },
  container: {
    flex: 1,
    alignItems: "center",
    padding: 20,
    backgroundColor: '#FFFFFF', // ì—¬ê¸°ì„œ ë°°ê²½ìƒ‰ì„ ì›í•˜ëŠ” ìƒ‰ìƒìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.
  },
  Btn: {
    backgroundColor: '#99aff8',
    width: width * 0.8,
    marginTop: 20,
  },
  buttonContainer: {
    flexDirection: 'row',
    justifyContent: 'space-around',
    width: '100%',
    marginVertical: 20,
  },
  image: {
    width: width *0.3,
    height: height *0.3,
    marginVertical: 20,
    resizeMode:"contain"
  },
  title: {
    fontSize: 24,
    fontWeight: 'bold',
    textAlign: 'center',
    marginBottom: 20,
  },
  prediction: {
    marginTop: 20,
    fontSize: 18,
  },
});

export default characterGAN;